__author__ = 'kolosnjaji'

from sklearn.svm import SVC
from sklearn.feature_extraction.text import CountVectorizer
from collections import Counter
from scipy.stats.stats import nanmean

import pickle
import numpy as np
import random
import sys

import copy

random.seed()

apicalls_file = open('/local_home/kolosnjaji/data/holmes_data/cuckoo_data/apicalls_all.txt', 'r')
all_sequences = apicalls_file.readlines()
sequences_split = []
sequences_split = [x.split() for x in all_sequences]

md5_file = open('/local_home/kolosnjaji/data/holmes_data/sha256list_virustotal.bin', 'rb')
md5_hashes = pickle.load(md5_file)

md5_dictionary_fs = pickle.load(open('/local_home/kolosnjaji/data/cluster_map_fs_holmes.bin','rb'))

my_counter = Counter(md5_dictionary_fs.values())

print my_counter

sequences_split_wf = []
md5_hashes_wf = []

trigram_vectorizer = CountVectorizer(ngram_range=(3, 3), token_pattern=r'\b\w+\b', min_df=1)
analyze = trigram_vectorizer.build_analyzer()


for hash in md5_dictionary_fs.keys():
    sequence_file = open('/local_home/kolosnjaji/data/holmes_data/cuckoo_data/' + hash.lower() + ".txt", 'r')
    sequence_split = sequence_file.readlines()
    if (len(sequence_split)>1000):
        sequence_split = sequence_split[0:1000]

    for j in range(len(sequence_split)):
        sequence_split[j] = sequence_split[j][0:-1] # strip the line terminators

    if (md5_dictionary_fs[hash]>-1):
        if sequence_split:
            sequences_split_wf.append(sequence_split)
            md5_hashes_wf.append(hash)
        else:
            pass

word_list = []
len_max = 0
for seq in sequences_split_wf:
    len_seq = len(seq)
    if (len_seq>len_max):
        len_max = len_seq
    for word in seq:
        if not word in word_list:
            word_list.append(word)

dict_size = len(word_list)

print "Word (unique system call) count: {0}".format(dict_size)

print "Maximal sequence length is: {0}".format(len_seq)

num_tests_nominal = 100

np.set_printoptions(precision=3, linewidth=150)

malware_dict_pattern = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]}

test_cuckoo_accuracy = copy.deepcopy(malware_dict_pattern)
test_peinfo_accuracy = copy.deepcopy(malware_dict_pattern)
test_yara_accuracy = copy.deepcopy(malware_dict_pattern)
test_average_accuracy = copy.deepcopy(malware_dict_pattern)
test_median_accuracy = copy.deepcopy(malware_dict_pattern)
test_majority_accuracy = copy.deepcopy(malware_dict_pattern)

num_families = len(malware_dict_pattern.keys())

confusion_matrix_majority = np.zeros((num_families, num_families))
confusion_matrix_average = np.zeros((num_families, num_families))
confusion_matrix_median = np.zeros((num_families, num_families))


num_families = len(malware_dict_pattern.keys())

precision_all_tests = []
recall_all_tests = []
accuracy_all_tests = []

[precision_all_tests.append([]) for i in range(0,num_families)]
[recall_all_tests.append([]) for i in range(0, num_families)]
[accuracy_all_tests.append([]) for i in range(0, num_families)]

for test in range(num_tests_nominal):

######################################### data preprocessing ######################################
    print "=================================TEST {0}=======================================".format(test)

    random_integers = range(len(sequences_split_wf)) # random indices for training and test set

    random.shuffle(random_integers)

    training_set_length = int(round(len(random_integers)*0.66))

    test_set_length = len(random_integers) - training_set_length

    print "Training set length:" + str(training_set_length)
    print "Test set length:" + str(test_set_length)

    malware_training_set = []
    malware_test_set = []

#    malware_training_set = np.zeros((training_set_length, len_max, dict_size))
#    malware_training_mask = np.zeros((training_set_length, len_max, dict_size))

    label_size = num_families

    malware_training_families = np.zeros(training_set_length)
    malware_test_families = np.zeros((test_set_length, label_size))


#    malware_test_set = np.zeros((test_set_length, len_max, dict_size))
#    malware_test_mask = np.zeros((test_set_length, len_max, dict_size))
    sequences_split_training = []
    doc_3grams_train = []
    for seq_index in range(0, training_set_length): # first create n-grams
        sequence = sequences_split_wf[random_integers[seq_index]]
        sequence_joined = " ".join(sequence)
        sequences_split_training.append(sequence_joined)
        doc_3grams_train.extend(analyze(sequence_joined))
        md5_hash_wf = md5_hashes_wf[random_integers[seq_index]]
        if (md5_hash_wf in md5_dictionary_fs):
            family = md5_dictionary_fs[md5_hash_wf]
            malware_training_families[seq_index]=family
            
        else:
            print "No family found, weird."

    doc_3grams_train = list(set(doc_3grams_train))
    fitted = trigram_vectorizer.fit(doc_3grams_train)
    
#    sequences_split_training = []
#    md5_hashes_training = []

#    dict_lengths = {}

#    sequences_training = {}    
    
    for seq_index in range(0, training_set_length): # create training set of sequences (sequences_split_training, malware_dict_train[family])
        if (md5_hash_wf in md5_dictionary_fs):
            #family = md5_dictionary_fs[md5_hash_wf]
            #malware_training_families.append(family)
            #malware_training_families[seq_index, family] = 1
            
            #malware_dict_train[family].append(random_indegers[seq_index])
            #print sequences_split_wf[random_integers[seq_index]]
#            print len(fitted.transform([sequences_split_training[seq_index]]).toarray())
            
            malware_training_set.append(fitted.transform([sequences_split_training[seq_index]]).toarray())

            

#            malware_training_mask[seq_index,:,:] = feature_mask[random_integers[seq_index], :,:]

        else:
            print "No family found, weird."

    malware_training_set = np.vstack(malware_training_set)


#    print "Number of training sequences: "  + str(len(sequences_split_training))
    # populate test sample set
    #
    sequences_split_test = []
    md5_hashes_test = []

    sequences_testing = {}



    for seq_index in range(training_set_length, len(random_integers)): # creating test set of sequences (sequences_split_test, malware_familites_test[family])
       sequence = sequences_split_wf[random_integers[seq_index]]
       sequence_joined = " ".join(sequence)
       sequences_split_test.append(sequence_joined)
       md5_hash = md5_hashes_wf[random_integers[seq_index]]
       if (md5_hash in md5_dictionary_fs):
          md5_hashes_test.append(md5_hash)
          family = md5_dictionary_fs[md5_hash]        
          malware_test_set.append(fitted.transform([sequence_joined]))        
          malware_test_families[training_set_length-seq_index] = family
          if (family in sequences_testing.keys()):
             sequences_testing[family].append(sequence_joined)
          else:
             sequences_testing[family] = [sequence_joined]
        

    i=0
    print "Number of test sequences: "  + str(len(sequences_split_test))

######################################### training ######################################
    print "**************************************TRAINING****************************************"

    mySVC = SVC(kernel='rbf')
    #print malware_training_set
    mySVC.fit(malware_training_set, malware_training_families)
    

###################################### testing ###########################################
    print "***********************************TESTING************************************"

    acc_attempts = np.zeros(num_families)
    acc_successes = np.zeros(num_families)
    accuracy = np.zeros(num_families)
    conf_matrix = np.zeros((num_families, num_families))
    
    for family in range(num_families): # for each testing family
        for sequence in sequences_testing[family]: # for each sequence in the family
            prob_family = []
            for model_family in range(num_families):
                max_family = mySVC.predict(fitted.transform([sequence]).toarray()) # has to be in n-grams
                if (max_family[0]==family):
                    acc_successes[family]+=1
                acc_attempts[family]+=1
     #           print max_family
                conf_matrix[family,max_family[0]]+=1
    

    precision_all = np.zeros(num_families)
    recall_all = np.zeros(num_families)

    for i in range(num_families):
        tp = conf_matrix[i,i]
        fn = 0
        fp = 0
        for j in range(num_families):
            if (j!=i):
                fn += conf_matrix[i, j]
                fp += conf_matrix[j,i]

        precision = tp/(tp+fp)
        recall = tp/(tp+fn)
        precision_all[i] = np.nan_to_num(precision)
        recall_all[i] = np.nan_to_num(recall)
        accuracy[i] = acc_successes[i]/float(acc_attempts[i])
        precision_all_tests[i].append(precision_all[i])
        recall_all_tests[i].append(recall_all[i])
        accuracy_all_tests[i].append(accuracy[i])

        print "{0} PR: {1} RC: {2} TP: {3} FP: {4}, FN: {5} ACC:{6} ".format(i, precision, recall, tp, fp, fn, accuracy[i])

    
    
    print "Average accuracy:" + str(np.nanmean(accuracy))
    print "Average precision:" + str(np.nanmean(precision_all))
    print "Average recall:" + str(np.nanmean(recall_all))
    print "Median precision:" + str(np.nanmedian(precision_all))
    print "Median recall:" + str(np.nanmedian(recall_all))
            
print [np.nanmean(precision) for precision in precision_all_tests]
print [np.nanmean(recall) for recall in recall_all_tests]                

pickle.dump((accuracy_all_tests, precision_all_tests, recall_all_tests), open('svm_out.bin', 'wb+'))

    





