__author__ = 'kolosnjaji'

##############################################################                                                                                                                         
# Code used for testing the SVM for malware classification, as a comparison to the neural network architecture                                                               
# Needed data: Windows API calls, malware ground truth labels                                                                                                                          
# Result: Model that assigns a label to previously unknown malware sample                                               
#############################################################    


from sklearn.svm import SVC
from sklearn.feature_extraction.text import CountVectorizer
from collections import Counter
from scipy.stats.stats import nanmean

import pickle
import numpy as np
import random
import sys

import copy

random.seed()

apicalls_file = open('/local_home/kolosnjaji/data/holmes_data/cuckoo_data/apicalls_all.txt', 'r')
all_sequences = apicalls_file.readlines()
sequences_split = []
sequences_split = [x.split() for x in all_sequences]

md5_file = open('/local_home/kolosnjaji/data/holmes_data/sha256list_virustotal.bin', 'rb')
md5_hashes = pickle.load(md5_file)

md5_dictionary_fs = pickle.load(open('/local_home/kolosnjaji/data/cluster_map_fs_holmes.bin','rb'))

my_counter = Counter(md5_dictionary_fs.values())

print my_counter

sequences_split_wf = []
md5_hashes_wf = []

trigram_vectorizer = CountVectorizer(ngram_range=(3, 3), token_pattern=r'\b\w+\b', min_df=1)
analyze = trigram_vectorizer.build_analyzer()


for hash in md5_dictionary_fs.keys():
    sequence_file = open('/local_home/kolosnjaji/data/holmes_data/cuckoo_data/' + hash.lower() + ".txt", 'r')
    sequence_split = sequence_file.readlines()
    if (len(sequence_split)>1000):
        sequence_split = sequence_split[0:1000]

    for j in range(len(sequence_split)):
        sequence_split[j] = sequence_split[j][0:-1] # strip the line terminators

    if (md5_dictionary_fs[hash]>-1):
        if sequence_split:
            sequences_split_wf.append(sequence_split)
            md5_hashes_wf.append(hash)
        else:
            pass

word_list = []
len_max = 0
for seq in sequences_split_wf:
    len_seq = len(seq)
    if (len_seq>len_max):
        len_max = len_seq
    for word in seq:
        if not word in word_list:
            word_list.append(word)

dict_size = len(word_list)

print "Word (unique system call) count: {0}".format(dict_size)

print "Maximal sequence length is: {0}".format(len_seq)

num_tests_nominal = 5

np.set_printoptions(precision=3, linewidth=150)

malware_dict_pattern = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]}

test_cuckoo_accuracy = copy.deepcopy(malware_dict_pattern)
test_peinfo_accuracy = copy.deepcopy(malware_dict_pattern)
test_yara_accuracy = copy.deepcopy(malware_dict_pattern)
test_average_accuracy = copy.deepcopy(malware_dict_pattern)
test_median_accuracy = copy.deepcopy(malware_dict_pattern)
test_majority_accuracy = copy.deepcopy(malware_dict_pattern)

num_families = len(malware_dict_pattern.keys())

confusion_matrix_majority = np.zeros((num_families, num_families))
confusion_matrix_average = np.zeros((num_families, num_families))
confusion_matrix_median = np.zeros((num_families, num_families))


num_families = len(malware_dict_pattern.keys())

precision_all_tests = []
recall_all_tests = []
accuracy_all_tests = []

[precision_all_tests.append([]) for i in range(0,num_families)]
[recall_all_tests.append([]) for i in range(0, num_families)]
[accuracy_all_tests.append([]) for i in range(0, num_families)]

cv_k=2

random.seed(1337)

for test in range(num_tests_nominal):

######################################### data preprocessing ######################################
    print "=================================TEST {0}=======================================".format(test)

    random_integers = range(len(sequences_split_wf)) # random indices for training and test set

    random.shuffle(random_integers)

    accuracy_cv = []
    precision_cv = []
    recall_cv = []

    num_indices = int(len(random_integers)/float(cv_k))

    print "Num indices {0}".format(num_indices)

    for cv_iter in range(cv_k):
        if (cv_iter+1)*num_indices > len(random_integers):
            max_num = len(random_integers)
        else:
            max_num = (cv_iter+1)*num_indices
        test_set_indices = random_integers[cv_iter*num_indices:max_num]
        training_set_indices = []
        for i in range(len(random_integers)):
            if not random_integers[i] in test_set_indices:
                training_set_indices.append(random_integers[i])
        training_set_length = len(training_set_indices)
        test_set_length = len(test_set_indices)

        print "Training set length:{0}".format(training_set_length)
        print "Test set length:{0}".format(test_set_length)



        malware_training_set = []
        malware_test_set = []

        label_size = num_families

        malware_training_families = np.zeros(training_set_length)
        malware_test_families = np.zeros((test_set_length, label_size))

        sequences_split_training = []
        doc_3grams_train = []
        for seq_index in range(0, training_set_length): # first create n-grams
           sequence = sequences_split_wf[training_set_indices[seq_index]]
           sequence_joined = " ".join(sequence)
           sequences_split_training.append(sequence_joined)
           doc_3grams_train.extend(analyze(sequence_joined))
           md5_hash_wf = md5_hashes_wf[training_set_indices[seq_index]]
           if (md5_hash_wf in md5_dictionary_fs):
               family = md5_dictionary_fs[md5_hash_wf]
               malware_training_families[seq_index]=family
            
           else:
               print "No family found, weird."

        doc_3grams_train = list(set(doc_3grams_train))
        fitted = trigram_vectorizer.fit(doc_3grams_train)
    
        for seq_index in range(0, training_set_length): # create training set of sequences (sequences_split_training, malware_dict_train[family])
           if (md5_hash_wf in md5_dictionary_fs):
            
               malware_training_set.append(fitted.transform([sequences_split_training[seq_index]]).toarray())

            
           else:
               print "No family found, weird."

        malware_training_set = np.vstack(malware_training_set)


        sequences_split_test = []
        md5_hashes_test = []

        sequences_testing = {}



        for seq_index in range(0, test_set_length): # creating test set of sequences (sequences_split_test, malware_familites_test[family])
            sequence = sequences_split_wf[test_set_indices[seq_index]]
            sequence_joined = " ".join(sequence)
            sequences_split_test.append(sequence_joined)
            md5_hash = md5_hashes_wf[test_set_indices[seq_index]]
            if (md5_hash in md5_dictionary_fs):
                md5_hashes_test.append(md5_hash)
                family = md5_dictionary_fs[md5_hash]        
                malware_test_set.append(fitted.transform([sequence_joined]))        
                malware_test_families[seq_index] = family
                if (family in sequences_testing.keys()):
                    sequences_testing[family].append(sequence_joined)
                else:
                    sequences_testing[family] = [sequence_joined]
        

        i=0
        print "Number of test sequences: "  + str(len(sequences_split_test))

######################################### training ######################################
        print "**************************************TRAINING****************************************"

        mySVC = SVC(kernel='rbf')
        mySVC.fit(malware_training_set, malware_training_families)
    

###################################### testing ###########################################
        print "***********************************TESTING************************************"

        acc_attempts = np.zeros(num_families)
        acc_successes = np.zeros(num_families)
        accuracy = np.zeros(num_families)
        conf_matrix = np.zeros((num_families, num_families))
    
        for family in range(num_families): # for each testing family
            for sequence in sequences_testing[family]: # for each sequence in the family
                prob_family = []
                for model_family in range(num_families):
                    max_family = mySVC.predict(fitted.transform([sequence]).toarray()) # has to be in n-grams
                    if (max_family[0]==family):
                        acc_successes[family]+=1
                    acc_attempts[family]+=1
                    conf_matrix[family,max_family[0]]+=1
    

        precision_all = np.zeros(num_families)
        recall_all = np.zeros(num_families)

        for i in range(num_families):
            tp = conf_matrix[i,i]
            fn = 0
            fp = 0
            for j in range(num_families):
                if (j!=i):
                    fn += conf_matrix[i, j]
                    fp += conf_matrix[j,i]

            precision = tp/(tp+fp)
            recall = tp/(tp+fn)
            precision_all[i] = np.nan_to_num(precision)
            recall_all[i] = np.nan_to_num(recall)
            accuracy[i] = acc_successes[i]/float(acc_attempts[i])
            precision_all_tests[i].append(precision_all[i])
            recall_all_tests[i].append(recall_all[i])
            accuracy_all_tests[i].append(accuracy[i])

            print "{0} PR: {1} RC: {2} TP: {3} FP: {4}, FN: {5} ACC:{6} ".format(i, precision, recall, tp, fp, fn, accuracy[i])

        accuracy_cv.append(accuracy_all_tests)
        precision_cv.append(precision_all_tests)
        recall_cv.append(recall_all_tests)    
    
        print "Average accuracy:" + str(np.nanmean(accuracy))
        print "Average precision:" + str(np.nanmean(precision_all))
        print "Average recall:" + str(np.nanmean(recall_all))
        print "Median precision:" + str(np.nanmedian(precision_all))
        print "Median recall:" + str(np.nanmedian(recall_all))
            
    print [np.nanmean(precision) for precision in precision_all_tests]
    print [np.nanmean(recall) for recall in recall_all_tests]                

    pickle.dump((accuracy_cv, precision_cv, recall_cv), open('svm_out_{0}.bin'.format(test), 'wb+'))

    





